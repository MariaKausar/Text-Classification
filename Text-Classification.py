# -*- coding: utf-8 -*-
"""Maria_Kausar.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q_YaqEqWUHOWRPPW2DlqSsWExC6mkqZ9
"""

globals().clear()  # clear all variables

# important lib
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
import matplotlib.pyplot as plt
import pandas as pd

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn import metrics

print("Version: ", tf.__version__)
print("Eager mode: ", tf.executing_eagerly())
print("Hub version: ", hub.__version__)
print("GPU is", "available" if tf.config.list_physical_devices('GPU') else "NOT AVAILABLE")

"""For rerunable, you can upload data on GitHub or can upload file manually in Google Colab"""

# set the percentages of training, validation and testing dataset
test_percentage = 0.1
validation_percentage = 0.1

# Read data generated from GitHub Account
import requests

url = 'https://raw.githubusercontent.com/Maria4Maria/NLP-dataset/main/Mental-Health-Twitter.csv'
response = requests.get(url)

if response.status_code == 200:
    with open('Mental-Health-Twitter.csv', 'wb') as file:
        file.write(response.content)
    print('CSV file downloaded successfully!')
else:
    print(f'Failed to download CSV file. Status code: {response.status_code}')

# read data from csv file
data = pd.read_csv('/content/Mental-Health-Twitter.csv')

# Display the first few lines of the dataset
print(data.head())

"""Preprocessing and data cleaning steps"""

data.drop(columns=['index','post_id','post_created','user_id','followers','friends','favourites','statuses','retweets'], inplace=True)
print(data.head(5))

print(data.columns)

data.dropna(inplace=True) # drop other columns

import re

# Remove integers
data['post_text'] = data['post_text'].apply(lambda x: re.sub(r'\d+', '', x))
data
# Remove special characters and punctuation marks
data['post_text'] = data['post_text'].apply(lambda x: re.sub(r'[^\w\s]', '', x))

"""Text Cleaning"""

#importing important libraries for preprocessing

import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

nltk.download('stopwords')
nltk.download('punkt')
stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

import re

def preprocess_text(text):
    text = re.sub(r'https?://\S+|www\.\S+', '', text)  # Remove URLs
    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove non-alphabetic characters
    text = text.lower()

    return text

data['post_text'] = data['post_text'].apply(preprocess_text)

stop = stopwords.words('english')
def clean_text(text):
  text = ' '.join([word for word in text.split() if word not in stop])
  return text

data["cleaned_text"] = data["post_text"].apply(clean_text)

#print(data['post_text'])
from nltk.tokenize import word_tokenize
data["tokens"] = data["cleaned_text"].apply(word_tokenize)

from sklearn.preprocessing import LabelEncoder

# Encoding the target variable
encoder = LabelEncoder()
data['label'] = encoder.fit_transform(data['label'])

import re
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

def preprocess_text(text):
    text = re.sub(r'https?://\S+|www\.\S+', '', text)  # Remove URLs
    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove non-alphabetic characters
    text = text.lower()

    # Additional steps
    text = re.sub(r'\d+', '', text)  # Remove numbers
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra whitespace
    tokens = word_tokenize(text)  # Tokenization
    stop_words = set(stopwords.words('english'))
    filtered_tokens = [word for word in tokens if word not in stop_words]  # Stopword removal
    stemmer = PorterStemmer()
    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]  # Stemming

    return ' '.join(stemmed_tokens)

from os import truncate
print(data.head(10)) # show 10 lines

X = data.tokens
y = data.label
print(X)
print("This is label: ",y)

import numpy as np
# Flatten the nested list
X_flat = np.concatenate(X)
# Filter out non-numeric values
X_numeric = [x for x in X_flat if isinstance(x, (int, float))]

# Convert the filtered values to integers
X_int = np.array(X_numeric).astype(int)

print(X_int)

# Partition the data into training and testing
test_examples = np.asarray(X[:round(test_percentage * len(X))])
train_examples = np.asarray(X[round(test_percentage * len(X)):])


test_labels = np.asarray(y[:round(test_percentage * len(X))])
train_labels = np.asarray(y[round(test_percentage * len(X)):])

print("Training entries: {}, test entries: {}".format(len(train_examples), len(test_examples)))

from sklearn.model_selection import train_test_split

# Assuming X is feature matrix and y is target vector
#X and y should be NumPy arrays or pandas DataFrames/Series
X_train, X_test, y_train, y_test = train_test_split(data['post_text'], data['label'], test_size=0.2, random_state=42)

# Build the model and show its layers; model has two fully connected layers with hidden units of 16 and 1, respectively

import time

# Start time measurement
start_time = time.time()


model = "https://tfhub.dev/google/nnlm-en-dim50/2"
hub_layer = hub.KerasLayer(model, input_shape=[], dtype=tf.string, trainable=True)

model = tf.keras.Sequential()
model.add(hub_layer)
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(1))  # because it's binary classification
model.summary()

# the loss function and metric are compatible with binary classification scenarios
model.compile(optimizer='adam',
              loss=tf.losses.BinaryCrossentropy(from_logits=True),
              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])

# extracting validation examples from the training data
x_val = X_train[:round(validation_percentage * len(X_train))]
partial_x_train = X_train[round(validation_percentage * len(X_train)):]

y_val = y_train[:round(validation_percentage * len(y_train))]
partial_y_train = y_train[round(validation_percentage * len(y_train)):]


# training the model
history = model.fit(partial_x_train,
                    partial_y_train,
                    epochs=10,
                    batch_size=512,
                    validation_data=(x_val, y_val),
                    verbose=1)

# see model training history
history_dict = history.history
history_dict.keys()

acc = history_dict['accuracy']
val_acc = history_dict['val_accuracy']
loss = history_dict['loss']
val_loss = history_dict['val_loss']

epochs = range(1, len(acc) + 1)

# "bo" is for "blue dot"
plt.plot(epochs, loss, 'bo', label='Training loss')
# b is for "solid blue line"
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

plt.clf()  # clear figure

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()



results = model.evaluate(X_test, y_test)  # this return loss value and accuracy
print(results)

# another method to evaluate performance
predictions = model.predict(X_test)
predictions[predictions >= 0] = 1
predictions[predictions < 0] = 0
confusionMatrix = confusion_matrix(y_test, predictions, normalize='pred')
acc = metrics.accuracy_score(y_test, predictions)
print(classification_report(y_test, predictions))

# End time measurement
end_time = time.time()

# Calculate the total training time
training_time = end_time - start_time
print("Total training time:", training_time, "seconds")

# Plot confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

# Build the model and show its layers; model has two fully connected layers with hidden units of 16 and 1, respectively

import time

# Start time measurement
start_time = time.time()

model2 = "https://tfhub.dev/google/nnlm-en-dim50-with-normalization/2"

hub_layer = hub.KerasLayer(model2, input_shape=[], dtype=tf.string, trainable=True)

model2 = tf.keras.Sequential()
model2.add(hub_layer)
model2.add(tf.keras.layers.Dense(16, activation='relu'))
model2.add(tf.keras.layers.Dense(1))  # because it's binary classification
model2.summary()

# the loss function and metric are compatible with binary classification scenarios
model2.compile(optimizer='adam',
              loss=tf.losses.BinaryCrossentropy(from_logits=True),
              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])

# extracting validation examples from the training data
x_val2 = X_train[:round(validation_percentage * len(X_train))]
partial_x_train2 = X_train[round(validation_percentage * len(X_train)):]

y_val2 = y_train[:round(validation_percentage * len(y_train))]
partial_y_train2 = y_train[round(validation_percentage * len(y_train)):]


# training the model
history = model2.fit(partial_x_train2,
                    partial_y_train2,
                    epochs=10,
                    batch_size=512,
                    validation_data=(x_val2, y_val2),
                    verbose=1)

# see model training history
history_dict = history.history
history_dict.keys()

acc = history_dict['accuracy']
val_acc = history_dict['val_accuracy']
loss = history_dict['loss']
val_loss = history_dict['val_loss']

epochs = range(1, len(acc) + 1)

# "bo" is for "blue dot"
plt.plot(epochs, loss, 'bo', label='Training loss')
# b is for "solid blue line"
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

plt.clf()  # clear figure

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()



results = model2.evaluate(X_test, y_test)  # this return loss value and accuracy
print(results)

# another method to evaluate performance
predictions2 = model2.predict(X_test)
predictions2[predictions2 >= 0] = 1
predictions2[predictions2 < 0] = 0
confusionMatrix = confusion_matrix(y_test, predictions2, normalize='pred')
acc = metrics.accuracy_score(y_test, predictions2)
print(classification_report(y_test, predictions2))

# End time measurement
end_time = time.time()

# Calculate the total training time
training_time = end_time - start_time
print("Total training time:", training_time, "seconds")

# Plot confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

# Build the model and show its layers; model has two fully connected layers with hidden units of 16 and 1, respectively

import time

# Start time measurement
start_time = time.time()

model = "https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2"


hub_layer = hub.KerasLayer(model, input_shape=[], dtype=tf.string, trainable=True)
# hub_layer(X_train[:3])
model = tf.keras.Sequential()
model.add(hub_layer)
model.add(tf.keras.layers.Dense(32, activation='relu')) # before 32
model.add(tf.keras.layers.Dense(1))  # because it's binary classification
model.summary()

# the loss function and metric are compatible with binary classification scenarios
model.compile(optimizer='adam',
              loss=tf.losses.BinaryCrossentropy(from_logits=True),
              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])

# extracting validation examples from the training data
x_val = X_train[:round(validation_percentage * len(X_train))]
partial_x_train = X_train[round(validation_percentage * len(X_train)):]

y_val = y_train[:round(validation_percentage * len(y_train))]
partial_y_train = y_train[round(validation_percentage * len(y_train)):]


# training the model
history = model.fit(partial_x_train,
                    partial_y_train,
                    epochs=10,
                    batch_size=512,
                    validation_data=(x_val, y_val),
                    verbose=1)

# see model training history
history_dict = history.history
history_dict.keys()

acc = history_dict['accuracy']
val_acc = history_dict['val_accuracy']
loss = history_dict['loss']
val_loss = history_dict['val_loss']

epochs = range(1, len(acc) + 1)

# "bo" is for "blue dot"
plt.plot(epochs, loss, 'bo', label='Training loss')
# b is for "solid blue line"
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

plt.clf()  # clear figure

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()



results = model.evaluate(X_test, y_test)  # this return loss value and accuracy
print(results)

# another method to evaluate performance
predictions = model.predict(X_test)
predictions[predictions >= 0] = 1
predictions[predictions < 0] = 0
confusionMatrix = confusion_matrix(y_test, predictions, normalize='pred')
acc = metrics.accuracy_score(y_test, predictions)
print(classification_report(y_test, predictions))

# End time measurement
end_time = time.time()

# Calculate the total training time
training_time = end_time - start_time
print("Total training time:", training_time, "seconds")

# Plot confusion matrix for Third model
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()